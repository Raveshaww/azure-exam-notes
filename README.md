# Preface
Working through John Savill's DevOps Master Class, A Cloud Guru, and some additional material via Microsoft Learn. 
# Notes
### Foundation
- Things like patching OS and whatnot don't really bring value to the org, hence why they tend to be avoided in DevOps
- SCRUM always contains **only** pull motions
- SCRUM contains sprints, which are a fixed duration of work
    - User stories, bugs, and tasks are in sprints
- SCRUM can use kanban boards, but they assign points to each item of work
    - Instead of WIP limits, they use point limits
- Generally, team sizes do not pass what you can feed with 2 pizzas
- Kanban is always in motion
- Pull when you have space
- Self-service is key to agility
### Mastering Git
- Centralized source control is generally not used anymore. This can be called `TFVC`
    - This requires someone to check out files in order to work on it, creating a lock on those files
- Git is distributed, since all devs have a copy of all files
    - You sync with the remote origin
- `git config` allows you to change some attributes, like `user.name`
- You can change the default branch name by the following:
    - `git config --global init.defaultBranch main`
- All objects in git end up stored as a blob
- All blobs have a hash (sha1)
- This hash is used to find changes
- A tree has a file name, and uses a file pointer to point to the blob
- A commit is a snapshot of the entire repo which points to a certain tree, and contains additional metadata like author and date
- `git init` created a `.git` subfolder
    - this has an `objects` folder
- You have a head for each branch
- The `HEAD` file points to the branch in use
- The `working directory` is where you actually work with the file
- You may not always want everything you're working on to go into the next commit, so you can instead `stage` or `index` these changes
    - This is `git add`
- A blob is created when something is staged
- To push to the repo, you use `git commit -m "test thing"`
- You can remove something from staging with `git rm`
    - This is staged, and requires a commit to actually delete from the repo (but not the history)
- To not remove from working, `git rm --cached`
- Sometimes you want to keep track of the history introduced by a branch.
    - In this scenario, you can simple merge without fast-forwarding via `git merge --no-ff`
- Rebase is like updating your branch based on the current version of main
    - Never rebase a public branch
### Azure DevOps and GitHub
- There's actually a pretty large amount of overlap between Azure DevOps and GitHub
- They are also tightly integrated.
    - For an example, GitHub repo with ADO pipelines
- It's a bit odd, but ADO prides itself in the fact that you don't need to use all of its services
- In GitHub, most additional workflow things live under the repo itself
- An `epic` is an organizational strategy / initiative that may impact multiple products, or be a long term strategy
    - These may need financial approval
    - Basically, designed to move the company forward
    - Basically, if you can't release something in a single release, it's probably an epic
- This breaks down into multiple `features`
    - This is part of the product roadmap
- These break down into `user stories`
    - This is what the delivery teams use
    - These should be releasable in a single cycle
    - These should have a title, description, and acceptance criteria
- Azure Boards have an idea of work items and boards
    - It natively has an idea of epics, features, user stories and more
- Tasks may be a subset of a user story
- You can add tags to elements, like tasks, in ADO
- You can create "swim lanes" with ADO Boards
- GitHub doesn't really have the concept of the above, but it can use labels and issues to facilitate similar things
- It also has the idea of projects, which lets you organize issues
- It also has discussion capabilities
- To create something similar to an epic in GitHub, you would create an issue and add a label
    - You would than create a milestone, and link that "epic" to the milestone
- You can set up templates to help the creation of things like feature requests in GitHub
- GitHub also has a basic wiki function
- If you're in a GitHub organization, you have an option to use a GitHub codespace
    - This is not free
- In GitHub organizations, you can have an "internal" repo
- Public repos in GH have the following for free:
    - Dependency graph
    - Dependabot alerts
    - Dependabot security updates
    - Code scanning
- You can have self hosted GitHub Action runners
- GHA is all YAML
- GHA is any event, and not just CI/CD
- GHA can let you designate a release branch
- An ADO artifact is like a .exe
- Github calls this a package
### ADO Boards from ACG
- ADO lets you build dashboards to help visualize progress
- ADO is the rebrand of Visual Studio Team Services
- ADO project hierarchy is:  
    - Organization > team project > team
- Team projects should be considered as impassible security boundaries 
- The advice is to create as few team projects as possible, ideally only one 
- There are four different type of work item processes in ADO
    - `agile` is pretty straightforward
    - `scrum` means that instead of `user stories` you have `pbi`
    - `cmmi` is not as well known, but the third level of work is a `requirement`
    - `basic` is only epic, issues, and tasks. Somewhat similar to GitHub?
- A basic user has access to all services except for `test plans`, and the first 5 are free
- Stakeholder licenses do not have access to source control, and are generally only for work management
- Area paths are used to associate work items with product areas
    - Backlogs are built from one or more area paths
- Iteration paths are like sprints
- You can set up different workflows to work items with the type of bugs
    - They can contain tasks, and be added to iterations
- You can only have one backlog per team
- When all tasks under a story are done, the story is **not** automatically marked as done
- Bugs are not enabled by default
### ADO Repos from ACG
- ADO supports TFVC
- GitHub flow is what Savill described
- GitFlow allows for more parallel feature development, but is otherwise the same as the above (three way merges galore)
- Trunk based development doesn't use any branch
- You can only have one TFVC repo, but you can have as many git repos as you want per ADO Project
### CI/CD
- Ideally, you have test cases and develop with those test cases to make sure you haven't broken anything
- An artifact could be an image, a dockerfile, a zip folder, etc
- You trigger CI on some sort of event, like a commit or a pull request
- A CI pipeline can handle dependency prep before building code
- It then runs automated tests
    - A failure can be configured to go and create a work item
- If it passes all the tests, it can create an artifact
- The end result will be that the artifact gets uploaded to some registry
- You could optionally create a release under certain conditions, like if it was off of main
- It's common for the upload of the artifact to be the trigger for a Continuous delivery pipeline
- Continuous delivery is **not** the deployment of the code
- Continuous deployment is the automated deployment of code to prod
- For CDel, you would have gates between each stage to progress it through the pipeline
- Ideally, you build each environment with IaC
- It is extremely important that all environments are consistent with production, but not necessarily equal
- Blue / green is basically two environments, and you only deploy to one environment and you start slowly moving people from one to the other
- Pools are the agents that you are going to use in a pipeline
- Stages will run sequentially unless specified otherwise
- You can tie gates to environments rather than something on the pipeline itself
- Microsoft-hosted agents are ephemeral, but things within the same stage can access the same files
- You can use the DevOps generator site to play around with ADO
    - `https://azuredevopsgeneratore.azurewebsites.net`
- GHA live in the `.github/workflows/` folder in your repo
- ADO agents and GHA runners don't make inbound connections from the internet to facilitate running on local VMs
- Actions are written in either JS or in a container
    - Think of it like YAML being the front end for Ansible's python backend
- You can set up matrixes to handle multiple different environments in one run (Both ADO and GHA)
### Analyzing Metrics
- `Azure Monitor` is a central hub for all info about infra, apps, and other Azure resources
    - This can be stored in two ways, `metrics` and `logs`
- You can use this to visualize and create dashboards
- You can also use this to create alerts
- You can also set up automated actions to automatically take action on alerts
- `Application insights` can track things like
    - request/failure rates
    - response times
    - page and user info
    - app exceptions
    - app dependencies 
    - performance info
- This is what Tomi used to set up URL ping tests
- For url/ping tests, you can change the status code that its expecting, or something the content must contain
- Failure mode analysis tries to find points of failure
    - Rates the risk and severity
    - Determine response (how the application will respond)
- You need to understand the application and the environment it's in
- You also need to understand the SLAs
- Is it critical?
- Is anything dependent on it?
- Implement fault domains where possible
    - Like where resources are hosted within a Data center (Availability Zones, for an example)
    - Cross region, or Azure Site Recovery
    - Autoscaling
- Why create a baseline
    - We can use a baseline to define what a healthy state is
- How do we create a baseline
    - Log Analytics and Metrics Explorer
    - Azure Monitor Insights
    - App Insights
- Azure Monitor Insights
    - It requires at least 8 days of telemetry at a sufficient volume to establish a baseline for performance
- Dynamic Threshold Advantages
    - The use ML to identify patterns and trends to help find anomalies 
    - Less manual work
    - Set it and forget it
- App Insights Smart Detection
    - Uses ML to analyze telemetry to detect anomalies
    - Tries to figure out why it's going wrong
    - It's built in, and requires no config
- Smart Detection Categories
    - It will calculate the expected number of failures, and alert should it reach a threshold
    - It will monitor and send alerts in real time
    - The alerts will actually provide context
    - In the case of failures, it needs 24 hours worth of data to start
- Failure rates are considered an alert
- App Insights Dependency Tracking
    - It can track and monitor calls to dependencies
    - It features automatic tracking with .net and .net core applications
    - You can also track AJAX calls
    - It will also automatically track HTTP and HTTPS calls, Azure storage calls, sql calls, eventhub client, and servicebus sdk
- Application dependencies on VMs
    - You first need to enable the agent